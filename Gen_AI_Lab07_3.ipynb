{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlG+2lbtRhcCrVrLTcXE0W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303a52157/Generative-AI_2025/blob/main/Gen_AI_Lab07_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHy91pK5ANL2",
        "outputId": "1ac0118d-a5c9-44db-e992-ce6d08abe59a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.3900 - loss: 0.6842 - val_accuracy: 0.3670 - val_loss: 0.6817\n",
            "Epoch 2/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3963 - loss: 0.6622 - val_accuracy: 0.3761 - val_loss: 0.6493\n",
            "Epoch 3/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4409 - loss: 0.6228 - val_accuracy: 0.3853 - val_loss: 0.6237\n",
            "Epoch 4/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4342 - loss: 0.6025 - val_accuracy: 0.3578 - val_loss: 0.6002\n",
            "Epoch 5/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4206 - loss: 0.5836 - val_accuracy: 0.3578 - val_loss: 0.5793\n",
            "Epoch 6/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4310 - loss: 0.5641 - val_accuracy: 0.3670 - val_loss: 0.5600\n",
            "Epoch 7/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4484 - loss: 0.5379 - val_accuracy: 0.3761 - val_loss: 0.5416\n",
            "Epoch 8/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4383 - loss: 0.5139 - val_accuracy: 0.3761 - val_loss: 0.5249\n",
            "Epoch 9/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4316 - loss: 0.5255 - val_accuracy: 0.3761 - val_loss: 0.5088\n",
            "Epoch 10/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4764 - loss: 0.4863 - val_accuracy: 0.3578 - val_loss: 0.4940\n",
            "Epoch 11/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4305 - loss: 0.4764 - val_accuracy: 0.3578 - val_loss: 0.4791\n",
            "Epoch 12/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4264 - loss: 0.4627 - val_accuracy: 0.3578 - val_loss: 0.4648\n",
            "Epoch 13/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4117 - loss: 0.4577 - val_accuracy: 0.3578 - val_loss: 0.4510\n",
            "Epoch 14/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4712 - loss: 0.4393 - val_accuracy: 0.3670 - val_loss: 0.4376\n",
            "Epoch 15/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3971 - loss: 0.4354 - val_accuracy: 0.3670 - val_loss: 0.4242\n",
            "Epoch 16/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4106 - loss: 0.3757 - val_accuracy: 0.3670 - val_loss: 0.4110\n",
            "Epoch 17/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4255 - loss: 0.4120 - val_accuracy: 0.3761 - val_loss: 0.3982\n",
            "Epoch 18/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4209 - loss: 0.3977 - val_accuracy: 0.3761 - val_loss: 0.3860\n",
            "Epoch 19/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4186 - loss: 0.3591 - val_accuracy: 0.3853 - val_loss: 0.3738\n",
            "Epoch 20/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4404 - loss: 0.4039 - val_accuracy: 0.3853 - val_loss: 0.3619\n",
            "Epoch 21/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4243 - loss: 0.3525 - val_accuracy: 0.3853 - val_loss: 0.3504\n",
            "Epoch 22/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4150 - loss: 0.3025 - val_accuracy: 0.3853 - val_loss: 0.3392\n",
            "Epoch 23/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3832 - loss: 0.3384 - val_accuracy: 0.3853 - val_loss: 0.3276\n",
            "Epoch 24/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4359 - loss: 0.2455 - val_accuracy: 0.3853 - val_loss: 0.3155\n",
            "Epoch 25/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4401 - loss: 0.3007 - val_accuracy: 0.3853 - val_loss: 0.3042\n",
            "Epoch 26/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3983 - loss: 0.2606 - val_accuracy: 0.3853 - val_loss: 0.2937\n",
            "Epoch 27/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4308 - loss: 0.2325 - val_accuracy: 0.3853 - val_loss: 0.2831\n",
            "Epoch 28/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4640 - loss: 0.2570 - val_accuracy: 0.3853 - val_loss: 0.2720\n",
            "Epoch 29/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4318 - loss: 0.2726 - val_accuracy: 0.3853 - val_loss: 0.2615\n",
            "Epoch 30/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4729 - loss: 0.3056 - val_accuracy: 0.3853 - val_loss: 0.2506\n",
            "Epoch 31/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4378 - loss: 0.1809 - val_accuracy: 0.3761 - val_loss: 0.2406\n",
            "Epoch 32/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4427 - loss: 0.2941 - val_accuracy: 0.3761 - val_loss: 0.2307\n",
            "Epoch 33/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4225 - loss: 0.1509 - val_accuracy: 0.3761 - val_loss: 0.2210\n",
            "Epoch 34/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4482 - loss: 0.1935 - val_accuracy: 0.3761 - val_loss: 0.2109\n",
            "Epoch 35/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4017 - loss: 0.1567 - val_accuracy: 0.3670 - val_loss: 0.2010\n",
            "Epoch 36/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4279 - loss: 0.2017 - val_accuracy: 0.3670 - val_loss: 0.1904\n",
            "Epoch 37/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4197 - loss: 0.1257 - val_accuracy: 0.3578 - val_loss: 0.1810\n",
            "Epoch 38/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4078 - loss: 0.1700 - val_accuracy: 0.3578 - val_loss: 0.1714\n",
            "Epoch 39/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4458 - loss: 0.2259 - val_accuracy: 0.3578 - val_loss: 0.1618\n",
            "Epoch 40/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4189 - loss: 0.1637 - val_accuracy: 0.3578 - val_loss: 0.1524\n",
            "Epoch 41/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4685 - loss: 0.1116 - val_accuracy: 0.3578 - val_loss: 0.1435\n",
            "Epoch 42/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4111 - loss: -0.0289 - val_accuracy: 0.3578 - val_loss: 0.1346\n",
            "Epoch 43/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4521 - loss: 0.0913 - val_accuracy: 0.3578 - val_loss: 0.1254\n",
            "Epoch 44/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4877 - loss: 0.0539 - val_accuracy: 0.3578 - val_loss: 0.1168\n",
            "Epoch 45/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4303 - loss: 0.1714 - val_accuracy: 0.3578 - val_loss: 0.1077\n",
            "Epoch 46/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4488 - loss: 0.1352 - val_accuracy: 0.3578 - val_loss: 0.0989\n",
            "Epoch 47/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4144 - loss: -0.0456 - val_accuracy: 0.3578 - val_loss: 0.0900\n",
            "Epoch 48/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4219 - loss: 0.0452 - val_accuracy: 0.3578 - val_loss: 0.0813\n",
            "Epoch 49/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4335 - loss: 0.0568 - val_accuracy: 0.3578 - val_loss: 0.0723\n",
            "Epoch 50/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4111 - loss: 0.0075 - val_accuracy: 0.3578 - val_loss: 0.0638\n",
            "Epoch 51/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4440 - loss: 0.0916 - val_accuracy: 0.3578 - val_loss: 0.0551\n",
            "Epoch 52/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3856 - loss: 0.0713 - val_accuracy: 0.3578 - val_loss: 0.0461\n",
            "Epoch 53/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4263 - loss: 0.0980 - val_accuracy: 0.3578 - val_loss: 0.0380\n",
            "Epoch 54/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3909 - loss: 0.0463 - val_accuracy: 0.3578 - val_loss: 0.0292\n",
            "Epoch 55/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4394 - loss: 7.9974e-04 - val_accuracy: 0.3578 - val_loss: 0.0210\n",
            "Epoch 56/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4246 - loss: -0.0557 - val_accuracy: 0.3578 - val_loss: 0.0128\n",
            "Epoch 57/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4479 - loss: 0.0111 - val_accuracy: 0.3578 - val_loss: 0.0045\n",
            "Epoch 58/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4654 - loss: 0.1037 - val_accuracy: 0.3578 - val_loss: -0.0037\n",
            "Epoch 59/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4180 - loss: -0.0992 - val_accuracy: 0.3578 - val_loss: -0.0118\n",
            "Epoch 60/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4478 - loss: -0.0629 - val_accuracy: 0.3578 - val_loss: -0.0200\n",
            "Epoch 61/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4254 - loss: -0.0592 - val_accuracy: 0.3578 - val_loss: -0.0279\n",
            "Epoch 62/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4017 - loss: -0.1013 - val_accuracy: 0.3578 - val_loss: -0.0358\n",
            "Epoch 63/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4692 - loss: -0.0357 - val_accuracy: 0.3578 - val_loss: -0.0438\n",
            "Epoch 64/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4142 - loss: -0.1246 - val_accuracy: 0.3578 - val_loss: -0.0517\n",
            "Epoch 65/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4454 - loss: -0.1402 - val_accuracy: 0.3578 - val_loss: -0.0590\n",
            "Epoch 66/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4148 - loss: -0.1817 - val_accuracy: 0.3578 - val_loss: -0.0674\n",
            "Epoch 67/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3769 - loss: -0.1815 - val_accuracy: 0.3578 - val_loss: -0.0753\n",
            "Epoch 68/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4477 - loss: 0.0516 - val_accuracy: 0.3578 - val_loss: -0.0832\n",
            "Epoch 69/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4712 - loss: -0.0785 - val_accuracy: 0.3578 - val_loss: -0.0910\n",
            "Epoch 70/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4319 - loss: -0.1175 - val_accuracy: 0.3578 - val_loss: -0.0987\n",
            "Epoch 71/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4520 - loss: -0.0205 - val_accuracy: 0.3578 - val_loss: -0.1068\n",
            "Epoch 72/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4261 - loss: -0.2211 - val_accuracy: 0.3578 - val_loss: -0.1149\n",
            "Epoch 73/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4341 - loss: -0.1911 - val_accuracy: 0.3578 - val_loss: -0.1230\n",
            "Epoch 74/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4385 - loss: -0.1280 - val_accuracy: 0.3578 - val_loss: -0.1307\n",
            "Epoch 75/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4317 - loss: -0.0750 - val_accuracy: 0.3578 - val_loss: -0.1384\n",
            "Epoch 76/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4057 - loss: -0.1371 - val_accuracy: 0.3578 - val_loss: -0.1464\n",
            "Epoch 77/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4662 - loss: -0.0762 - val_accuracy: 0.3578 - val_loss: -0.1543\n",
            "Epoch 78/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4220 - loss: -0.2049 - val_accuracy: 0.3578 - val_loss: -0.1625\n",
            "Epoch 79/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4380 - loss: -0.1154 - val_accuracy: 0.3578 - val_loss: -0.1705\n",
            "Epoch 80/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4383 - loss: -0.1923 - val_accuracy: 0.3578 - val_loss: -0.1783\n",
            "Epoch 81/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4469 - loss: -0.0363 - val_accuracy: 0.3578 - val_loss: -0.1864\n",
            "Epoch 82/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4229 - loss: -0.2243 - val_accuracy: 0.3578 - val_loss: -0.1947\n",
            "Epoch 83/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4471 - loss: -0.3012 - val_accuracy: 0.3578 - val_loss: -0.2021\n",
            "Epoch 84/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4288 - loss: -0.3497 - val_accuracy: 0.3578 - val_loss: -0.2098\n",
            "Epoch 85/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4341 - loss: -0.1865 - val_accuracy: 0.3578 - val_loss: -0.2172\n",
            "Epoch 86/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4154 - loss: -0.0769 - val_accuracy: 0.3578 - val_loss: -0.2253\n",
            "Epoch 87/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4537 - loss: -0.2554 - val_accuracy: 0.3578 - val_loss: -0.2331\n",
            "Epoch 88/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4384 - loss: -0.2694 - val_accuracy: 0.3578 - val_loss: -0.2407\n",
            "Epoch 89/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4666 - loss: -0.3729 - val_accuracy: 0.3578 - val_loss: -0.2489\n",
            "Epoch 90/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4386 - loss: -0.2296 - val_accuracy: 0.3578 - val_loss: -0.2562\n",
            "Epoch 91/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4507 - loss: -0.1643 - val_accuracy: 0.3578 - val_loss: -0.2637\n",
            "Epoch 92/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4175 - loss: -0.6500 - val_accuracy: 0.3578 - val_loss: -0.2707\n",
            "Epoch 93/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4307 - loss: -0.3608 - val_accuracy: 0.3578 - val_loss: -0.2786\n",
            "Epoch 94/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4440 - loss: -0.2928 - val_accuracy: 0.3578 - val_loss: -0.2864\n",
            "Epoch 95/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4158 - loss: -0.3522 - val_accuracy: 0.3578 - val_loss: -0.2947\n",
            "Epoch 96/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4444 - loss: -0.3578 - val_accuracy: 0.3578 - val_loss: -0.3028\n",
            "Epoch 97/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4307 - loss: -0.3562 - val_accuracy: 0.3578 - val_loss: -0.3106\n",
            "Epoch 98/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4415 - loss: -0.4963 - val_accuracy: 0.3578 - val_loss: -0.3184\n",
            "Epoch 99/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4252 - loss: -0.2030 - val_accuracy: 0.3578 - val_loss: -0.3259\n",
            "Epoch 100/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4054 - loss: -0.4815 - val_accuracy: 0.3578 - val_loss: -0.3338\n",
            "Epoch 101/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4160 - loss: -0.4480 - val_accuracy: 0.3578 - val_loss: -0.3413\n",
            "Epoch 102/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4185 - loss: -0.5795 - val_accuracy: 0.3578 - val_loss: -0.3485\n",
            "Epoch 103/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4173 - loss: -0.5062 - val_accuracy: 0.3578 - val_loss: -0.3569\n",
            "Epoch 104/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4063 - loss: -0.3835 - val_accuracy: 0.3578 - val_loss: -0.3644\n",
            "Epoch 105/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4205 - loss: -0.3022 - val_accuracy: 0.3578 - val_loss: -0.3723\n",
            "Epoch 106/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4544 - loss: -0.5251 - val_accuracy: 0.3578 - val_loss: -0.3798\n",
            "Epoch 107/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4052 - loss: -0.4507 - val_accuracy: 0.3578 - val_loss: -0.3876\n",
            "Epoch 108/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4362 - loss: -0.5283 - val_accuracy: 0.3578 - val_loss: -0.3956\n",
            "Epoch 109/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4129 - loss: -0.4145 - val_accuracy: 0.3578 - val_loss: -0.4037\n",
            "Epoch 110/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4511 - loss: -0.5507 - val_accuracy: 0.3578 - val_loss: -0.4116\n",
            "Epoch 111/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4499 - loss: -0.4513 - val_accuracy: 0.3578 - val_loss: -0.4196\n",
            "Epoch 112/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4323 - loss: -0.3340 - val_accuracy: 0.3578 - val_loss: -0.4275\n",
            "Epoch 113/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4357 - loss: -0.5496 - val_accuracy: 0.3578 - val_loss: -0.4356\n",
            "Epoch 114/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4280 - loss: -0.4150 - val_accuracy: 0.3578 - val_loss: -0.4436\n",
            "Epoch 115/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4303 - loss: -0.4633 - val_accuracy: 0.3578 - val_loss: -0.4510\n",
            "Epoch 116/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4147 - loss: -0.5744 - val_accuracy: 0.3578 - val_loss: -0.4590\n",
            "Epoch 117/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4299 - loss: -0.6600 - val_accuracy: 0.3578 - val_loss: -0.4669\n",
            "Epoch 118/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4413 - loss: -0.5023 - val_accuracy: 0.3578 - val_loss: -0.4752\n",
            "Epoch 119/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4351 - loss: -0.5517 - val_accuracy: 0.3578 - val_loss: -0.4831\n",
            "Epoch 120/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4348 - loss: -0.6121 - val_accuracy: 0.3578 - val_loss: -0.4909\n",
            "Epoch 121/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4225 - loss: -0.6881 - val_accuracy: 0.3578 - val_loss: -0.4986\n",
            "Epoch 122/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4518 - loss: -0.5354 - val_accuracy: 0.3578 - val_loss: -0.5072\n",
            "Epoch 123/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4202 - loss: -0.6883 - val_accuracy: 0.3578 - val_loss: -0.5151\n",
            "Epoch 124/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4416 - loss: -0.4528 - val_accuracy: 0.3578 - val_loss: -0.5234\n",
            "Epoch 125/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4073 - loss: -0.8577 - val_accuracy: 0.3578 - val_loss: -0.5309\n",
            "Epoch 126/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4701 - loss: -0.6413 - val_accuracy: 0.3578 - val_loss: -0.5394\n",
            "Epoch 127/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3794 - loss: -0.7191 - val_accuracy: 0.3578 - val_loss: -0.5476\n",
            "Epoch 128/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3943 - loss: -0.7285 - val_accuracy: 0.3578 - val_loss: -0.5548\n",
            "Epoch 129/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4313 - loss: -0.4691 - val_accuracy: 0.3578 - val_loss: -0.5627\n",
            "Epoch 130/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4255 - loss: -0.8190 - val_accuracy: 0.3578 - val_loss: -0.5710\n",
            "Epoch 131/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4393 - loss: -0.2354 - val_accuracy: 0.3578 - val_loss: -0.5790\n",
            "Epoch 132/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4521 - loss: -0.5239 - val_accuracy: 0.3578 - val_loss: -0.5870\n",
            "Epoch 133/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4089 - loss: -0.8633 - val_accuracy: 0.3578 - val_loss: -0.5948\n",
            "Epoch 134/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3968 - loss: -0.5315 - val_accuracy: 0.3578 - val_loss: -0.6030\n",
            "Epoch 135/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4185 - loss: -0.7530 - val_accuracy: 0.3578 - val_loss: -0.6110\n",
            "Epoch 136/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4543 - loss: -0.9325 - val_accuracy: 0.3578 - val_loss: -0.6191\n",
            "Epoch 137/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4536 - loss: -0.6822 - val_accuracy: 0.3578 - val_loss: -0.6270\n",
            "Epoch 138/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4486 - loss: -0.5938 - val_accuracy: 0.3578 - val_loss: -0.6356\n",
            "Epoch 139/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4418 - loss: -0.7222 - val_accuracy: 0.3578 - val_loss: -0.6442\n",
            "Epoch 140/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4260 - loss: -0.6955 - val_accuracy: 0.3578 - val_loss: -0.6521\n",
            "Epoch 141/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4560 - loss: -0.8086 - val_accuracy: 0.3578 - val_loss: -0.6613\n",
            "Epoch 142/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4368 - loss: -0.8034 - val_accuracy: 0.3578 - val_loss: -0.6690\n",
            "Epoch 143/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4371 - loss: -0.6409 - val_accuracy: 0.3578 - val_loss: -0.6771\n",
            "Epoch 144/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4656 - loss: -0.4733 - val_accuracy: 0.3578 - val_loss: -0.6854\n",
            "Epoch 145/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4590 - loss: -0.8068 - val_accuracy: 0.3578 - val_loss: -0.6941\n",
            "Epoch 146/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3905 - loss: -0.5944 - val_accuracy: 0.3578 - val_loss: -0.7027\n",
            "Epoch 147/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3952 - loss: -0.9641 - val_accuracy: 0.3578 - val_loss: -0.7114\n",
            "Epoch 148/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4203 - loss: -0.9696 - val_accuracy: 0.3578 - val_loss: -0.7207\n",
            "Epoch 149/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4622 - loss: -1.1357 - val_accuracy: 0.3578 - val_loss: -0.7288\n",
            "Epoch 150/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4606 - loss: -0.7609 - val_accuracy: 0.3578 - val_loss: -0.7373\n",
            "Epoch 151/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4110 - loss: -1.3912 - val_accuracy: 0.3578 - val_loss: -0.7457\n",
            "Epoch 152/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4248 - loss: -0.9574 - val_accuracy: 0.3578 - val_loss: -0.7544\n",
            "Epoch 153/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4452 - loss: -1.1051 - val_accuracy: 0.3578 - val_loss: -0.7629\n",
            "Epoch 154/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4600 - loss: -1.1300 - val_accuracy: 0.3578 - val_loss: -0.7715\n",
            "Epoch 155/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4108 - loss: -1.4524 - val_accuracy: 0.3578 - val_loss: -0.7791\n",
            "Epoch 156/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4280 - loss: -1.0000 - val_accuracy: 0.3578 - val_loss: -0.7883\n",
            "Epoch 157/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4117 - loss: -0.8387 - val_accuracy: 0.3578 - val_loss: -0.7972\n",
            "Epoch 158/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4207 - loss: -0.9809 - val_accuracy: 0.3578 - val_loss: -0.8061\n",
            "Epoch 159/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4308 - loss: -1.0261 - val_accuracy: 0.3578 - val_loss: -0.8145\n",
            "Epoch 160/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4261 - loss: -0.9366 - val_accuracy: 0.3578 - val_loss: -0.8234\n",
            "Epoch 161/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4388 - loss: -0.8637 - val_accuracy: 0.3578 - val_loss: -0.8320\n",
            "Epoch 162/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4244 - loss: -0.5361 - val_accuracy: 0.3578 - val_loss: -0.8409\n",
            "Epoch 163/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4056 - loss: -1.0919 - val_accuracy: 0.3578 - val_loss: -0.8506\n",
            "Epoch 164/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3981 - loss: -1.4569 - val_accuracy: 0.3578 - val_loss: -0.8587\n",
            "Epoch 165/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4544 - loss: -0.7063 - val_accuracy: 0.3578 - val_loss: -0.8678\n",
            "Epoch 166/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4321 - loss: -0.9179 - val_accuracy: 0.3578 - val_loss: -0.8768\n",
            "Epoch 167/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4533 - loss: -0.8041 - val_accuracy: 0.3578 - val_loss: -0.8862\n",
            "Epoch 168/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3811 - loss: -1.1678 - val_accuracy: 0.3578 - val_loss: -0.8953\n",
            "Epoch 169/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4415 - loss: -0.9640 - val_accuracy: 0.3578 - val_loss: -0.9047\n",
            "Epoch 170/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4070 - loss: -1.5093 - val_accuracy: 0.3578 - val_loss: -0.9138\n",
            "Epoch 171/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4242 - loss: -1.1422 - val_accuracy: 0.3578 - val_loss: -0.9234\n",
            "Epoch 172/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4216 - loss: -0.7948 - val_accuracy: 0.3578 - val_loss: -0.9321\n",
            "Epoch 173/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4279 - loss: -1.1783 - val_accuracy: 0.3578 - val_loss: -0.9420\n",
            "Epoch 174/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4320 - loss: -1.2802 - val_accuracy: 0.3578 - val_loss: -0.9516\n",
            "Epoch 175/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4482 - loss: -1.0428 - val_accuracy: 0.3578 - val_loss: -0.9618\n",
            "Epoch 176/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4154 - loss: -1.0891 - val_accuracy: 0.3578 - val_loss: -0.9710\n",
            "Epoch 177/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4425 - loss: -1.2316 - val_accuracy: 0.3578 - val_loss: -0.9806\n",
            "Epoch 178/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4462 - loss: -0.9218 - val_accuracy: 0.3578 - val_loss: -0.9907\n",
            "Epoch 179/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4229 - loss: -1.0083 - val_accuracy: 0.3578 - val_loss: -1.0004\n",
            "Epoch 180/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4212 - loss: -1.7305 - val_accuracy: 0.3578 - val_loss: -1.0103\n",
            "Epoch 181/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4580 - loss: -1.4272 - val_accuracy: 0.3578 - val_loss: -1.0194\n",
            "Epoch 182/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4233 - loss: -1.2809 - val_accuracy: 0.3578 - val_loss: -1.0289\n",
            "Epoch 183/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4194 - loss: -1.1727 - val_accuracy: 0.3578 - val_loss: -1.0385\n",
            "Epoch 184/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4224 - loss: -1.0931 - val_accuracy: 0.3578 - val_loss: -1.0482\n",
            "Epoch 185/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4576 - loss: -0.8513 - val_accuracy: 0.3578 - val_loss: -1.0581\n",
            "Epoch 186/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4315 - loss: -1.1596 - val_accuracy: 0.3578 - val_loss: -1.0675\n",
            "Epoch 187/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4591 - loss: -1.1921 - val_accuracy: 0.3578 - val_loss: -1.0777\n",
            "Epoch 188/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4346 - loss: -0.9900 - val_accuracy: 0.3578 - val_loss: -1.0879\n",
            "Epoch 189/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4088 - loss: -1.5980 - val_accuracy: 0.3578 - val_loss: -1.0978\n",
            "Epoch 190/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4344 - loss: -1.5261 - val_accuracy: 0.3578 - val_loss: -1.1079\n",
            "Epoch 191/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4273 - loss: -1.1519 - val_accuracy: 0.3578 - val_loss: -1.1182\n",
            "Epoch 192/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4177 - loss: -0.8726 - val_accuracy: 0.3578 - val_loss: -1.1282\n",
            "Epoch 193/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4234 - loss: -1.3118 - val_accuracy: 0.3578 - val_loss: -1.1381\n",
            "Epoch 194/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4222 - loss: -1.3306 - val_accuracy: 0.3578 - val_loss: -1.1483\n",
            "Epoch 195/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4320 - loss: -1.1073 - val_accuracy: 0.3578 - val_loss: -1.1584\n",
            "Epoch 196/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4543 - loss: -1.7268 - val_accuracy: 0.3578 - val_loss: -1.1685\n",
            "Epoch 197/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4131 - loss: -1.3449 - val_accuracy: 0.3578 - val_loss: -1.1797\n",
            "Epoch 198/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4332 - loss: -1.3904 - val_accuracy: 0.3578 - val_loss: -1.1893\n",
            "Epoch 199/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4290 - loss: -1.0837 - val_accuracy: 0.3578 - val_loss: -1.1998\n",
            "Epoch 200/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4693 - loss: -1.1470 - val_accuracy: 0.3578 - val_loss: -1.2114\n",
            "Epoch 201/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4142 - loss: -1.3951 - val_accuracy: 0.3578 - val_loss: -1.2220\n",
            "Epoch 202/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4261 - loss: -1.3987 - val_accuracy: 0.3578 - val_loss: -1.2323\n",
            "Epoch 203/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4237 - loss: -1.4374 - val_accuracy: 0.3578 - val_loss: -1.2434\n",
            "Epoch 204/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4382 - loss: -1.6098 - val_accuracy: 0.3578 - val_loss: -1.2538\n",
            "Epoch 205/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4221 - loss: -1.6058 - val_accuracy: 0.3578 - val_loss: -1.2641\n",
            "Epoch 206/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4294 - loss: -1.5448 - val_accuracy: 0.3578 - val_loss: -1.2746\n",
            "Epoch 207/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4377 - loss: -1.5657 - val_accuracy: 0.3578 - val_loss: -1.2847\n",
            "Epoch 208/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4290 - loss: -1.3772 - val_accuracy: 0.3578 - val_loss: -1.2950\n",
            "Epoch 209/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4065 - loss: -1.7609 - val_accuracy: 0.3578 - val_loss: -1.3060\n",
            "Epoch 210/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4331 - loss: -1.5157 - val_accuracy: 0.3578 - val_loss: -1.3178\n",
            "Epoch 211/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4509 - loss: -1.4477 - val_accuracy: 0.3578 - val_loss: -1.3285\n",
            "Epoch 212/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4436 - loss: -1.6009 - val_accuracy: 0.3578 - val_loss: -1.3398\n",
            "Epoch 213/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4628 - loss: -1.1825 - val_accuracy: 0.3578 - val_loss: -1.3507\n",
            "Epoch 214/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4438 - loss: -1.8724 - val_accuracy: 0.3578 - val_loss: -1.3617\n",
            "Epoch 215/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4093 - loss: -1.9041 - val_accuracy: 0.3578 - val_loss: -1.3726\n",
            "Epoch 216/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4015 - loss: -1.6966 - val_accuracy: 0.3578 - val_loss: -1.3839\n",
            "Epoch 217/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4347 - loss: -1.1950 - val_accuracy: 0.3578 - val_loss: -1.3962\n",
            "Epoch 218/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4331 - loss: -1.9896 - val_accuracy: 0.3578 - val_loss: -1.4080\n",
            "Epoch 219/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4296 - loss: -1.5491 - val_accuracy: 0.3578 - val_loss: -1.4198\n",
            "Epoch 220/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4605 - loss: -1.6365 - val_accuracy: 0.3578 - val_loss: -1.4320\n",
            "Epoch 221/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3964 - loss: -1.0043 - val_accuracy: 0.3578 - val_loss: -1.4430\n",
            "Epoch 222/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4683 - loss: -1.5271 - val_accuracy: 0.3578 - val_loss: -1.4545\n",
            "Epoch 223/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4123 - loss: -1.1540 - val_accuracy: 0.3578 - val_loss: -1.4657\n",
            "Epoch 224/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4469 - loss: -1.5677 - val_accuracy: 0.3578 - val_loss: -1.4773\n",
            "Epoch 225/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4325 - loss: -1.9019 - val_accuracy: 0.3578 - val_loss: -1.4883\n",
            "Epoch 226/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4489 - loss: -1.7296 - val_accuracy: 0.3578 - val_loss: -1.5001\n",
            "Epoch 227/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4743 - loss: -1.3203 - val_accuracy: 0.3578 - val_loss: -1.5108\n",
            "Epoch 228/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4540 - loss: -1.9334 - val_accuracy: 0.3578 - val_loss: -1.5224\n",
            "Epoch 229/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4306 - loss: -2.2049 - val_accuracy: 0.3578 - val_loss: -1.5347\n",
            "Epoch 230/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3629 - loss: -2.3174 - val_accuracy: 0.3578 - val_loss: -1.5466\n",
            "Epoch 231/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4152 - loss: -2.0949 - val_accuracy: 0.3578 - val_loss: -1.5591\n",
            "Epoch 232/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4089 - loss: -2.2254 - val_accuracy: 0.3578 - val_loss: -1.5710\n",
            "Epoch 233/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4023 - loss: -2.3148 - val_accuracy: 0.3578 - val_loss: -1.5826\n",
            "Epoch 234/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4225 - loss: -2.1008 - val_accuracy: 0.3578 - val_loss: -1.5937\n",
            "Epoch 235/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4539 - loss: -1.9801 - val_accuracy: 0.3578 - val_loss: -1.6059\n",
            "Epoch 236/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4680 - loss: -1.3967 - val_accuracy: 0.3578 - val_loss: -1.6186\n",
            "Epoch 237/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4225 - loss: -2.3588 - val_accuracy: 0.3578 - val_loss: -1.6300\n",
            "Epoch 238/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4576 - loss: -1.8342 - val_accuracy: 0.3578 - val_loss: -1.6418\n",
            "Epoch 239/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3942 - loss: -1.8543 - val_accuracy: 0.3578 - val_loss: -1.6542\n",
            "Epoch 240/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4227 - loss: -1.7806 - val_accuracy: 0.3578 - val_loss: -1.6657\n",
            "Epoch 241/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4530 - loss: -1.6639 - val_accuracy: 0.3578 - val_loss: -1.6779\n",
            "Epoch 242/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4075 - loss: -2.1382 - val_accuracy: 0.3578 - val_loss: -1.6898\n",
            "Epoch 243/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4319 - loss: -1.7117 - val_accuracy: 0.3578 - val_loss: -1.7017\n",
            "Epoch 244/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4269 - loss: -2.1996 - val_accuracy: 0.3578 - val_loss: -1.7139\n",
            "Epoch 245/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.3967 - loss: -1.6765 - val_accuracy: 0.3578 - val_loss: -1.7249\n",
            "Epoch 246/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4033 - loss: -2.0096 - val_accuracy: 0.3578 - val_loss: -1.7362\n",
            "Epoch 247/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4056 - loss: -1.7191 - val_accuracy: 0.3578 - val_loss: -1.7490\n",
            "Epoch 248/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4229 - loss: -1.6525 - val_accuracy: 0.3578 - val_loss: -1.7618\n",
            "Epoch 249/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4058 - loss: -2.4318 - val_accuracy: 0.3578 - val_loss: -1.7739\n",
            "Epoch 250/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4849 - loss: -2.2275 - val_accuracy: 0.3578 - val_loss: -1.7861\n",
            "Epoch 251/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4496 - loss: -1.6771 - val_accuracy: 0.3578 - val_loss: -1.7991\n",
            "Epoch 252/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4494 - loss: -1.9606 - val_accuracy: 0.3578 - val_loss: -1.8114\n",
            "Epoch 253/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4015 - loss: -2.5814 - val_accuracy: 0.3578 - val_loss: -1.8232\n",
            "Epoch 254/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4569 - loss: -2.2659 - val_accuracy: 0.3578 - val_loss: -1.8365\n",
            "Epoch 255/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5010 - loss: -1.7963 - val_accuracy: 0.3578 - val_loss: -1.8479\n",
            "Epoch 256/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4652 - loss: -2.2096 - val_accuracy: 0.3578 - val_loss: -1.8620\n",
            "Epoch 257/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4616 - loss: -1.6630 - val_accuracy: 0.3578 - val_loss: -1.8747\n",
            "Epoch 258/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4191 - loss: -2.7073 - val_accuracy: 0.3578 - val_loss: -1.8869\n",
            "Epoch 259/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4592 - loss: -2.5538 - val_accuracy: 0.3578 - val_loss: -1.8999\n",
            "Epoch 260/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4130 - loss: -2.1821 - val_accuracy: 0.3578 - val_loss: -1.9115\n",
            "Epoch 261/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4658 - loss: -1.8242 - val_accuracy: 0.3578 - val_loss: -1.9230\n",
            "Epoch 262/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3866 - loss: -2.7971 - val_accuracy: 0.3578 - val_loss: -1.9355\n",
            "Epoch 263/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4476 - loss: -2.2135 - val_accuracy: 0.3578 - val_loss: -1.9466\n",
            "Epoch 264/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4183 - loss: -3.0917 - val_accuracy: 0.3578 - val_loss: -1.9593\n",
            "Epoch 265/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3989 - loss: -2.1142 - val_accuracy: 0.3578 - val_loss: -1.9719\n",
            "Epoch 266/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4244 - loss: -2.4667 - val_accuracy: 0.3578 - val_loss: -1.9851\n",
            "Epoch 267/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4439 - loss: -2.2728 - val_accuracy: 0.3578 - val_loss: -1.9988\n",
            "Epoch 268/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4196 - loss: -2.7742 - val_accuracy: 0.3578 - val_loss: -2.0111\n",
            "Epoch 269/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4289 - loss: -1.9831 - val_accuracy: 0.3578 - val_loss: -2.0254\n",
            "Epoch 270/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4193 - loss: -2.6392 - val_accuracy: 0.3578 - val_loss: -2.0390\n",
            "Epoch 271/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4272 - loss: -2.0187 - val_accuracy: 0.3578 - val_loss: -2.0528\n",
            "Epoch 272/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4516 - loss: -2.1186 - val_accuracy: 0.3578 - val_loss: -2.0651\n",
            "Epoch 273/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4186 - loss: -3.4772 - val_accuracy: 0.3578 - val_loss: -2.0796\n",
            "Epoch 274/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4145 - loss: -3.0327 - val_accuracy: 0.3578 - val_loss: -2.0926\n",
            "Epoch 275/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4428 - loss: -2.3381 - val_accuracy: 0.3578 - val_loss: -2.1060\n",
            "Epoch 276/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4363 - loss: -2.5340 - val_accuracy: 0.3578 - val_loss: -2.1193\n",
            "Epoch 277/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3863 - loss: -2.2572 - val_accuracy: 0.3578 - val_loss: -2.1324\n",
            "Epoch 278/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4635 - loss: -2.6500 - val_accuracy: 0.3578 - val_loss: -2.1450\n",
            "Epoch 279/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4412 - loss: -2.1933 - val_accuracy: 0.3578 - val_loss: -2.1592\n",
            "Epoch 280/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4288 - loss: -2.4264 - val_accuracy: 0.3578 - val_loss: -2.1730\n",
            "Epoch 281/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4341 - loss: -2.8280 - val_accuracy: 0.3578 - val_loss: -2.1870\n",
            "Epoch 282/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4032 - loss: -3.3092 - val_accuracy: 0.3578 - val_loss: -2.2015\n",
            "Epoch 283/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4529 - loss: -2.4078 - val_accuracy: 0.3578 - val_loss: -2.2152\n",
            "Epoch 284/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4120 - loss: -2.6176 - val_accuracy: 0.3578 - val_loss: -2.2290\n",
            "Epoch 285/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4103 - loss: -3.0877 - val_accuracy: 0.3578 - val_loss: -2.2425\n",
            "Epoch 286/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4431 - loss: -3.2045 - val_accuracy: 0.3578 - val_loss: -2.2554\n",
            "Epoch 287/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4451 - loss: -2.7892 - val_accuracy: 0.3578 - val_loss: -2.2694\n",
            "Epoch 288/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4275 - loss: -1.9455 - val_accuracy: 0.3578 - val_loss: -2.2831\n",
            "Epoch 289/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4459 - loss: -3.3973 - val_accuracy: 0.3578 - val_loss: -2.2976\n",
            "Epoch 290/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4040 - loss: -3.0346 - val_accuracy: 0.3578 - val_loss: -2.3119\n",
            "Epoch 291/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4414 - loss: -2.7593 - val_accuracy: 0.3578 - val_loss: -2.3252\n",
            "Epoch 292/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4439 - loss: -2.2221 - val_accuracy: 0.3578 - val_loss: -2.3390\n",
            "Epoch 293/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4078 - loss: -2.2718 - val_accuracy: 0.3578 - val_loss: -2.3540\n",
            "Epoch 294/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4217 - loss: -2.5215 - val_accuracy: 0.3578 - val_loss: -2.3670\n",
            "Epoch 295/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4425 - loss: -2.3912 - val_accuracy: 0.3578 - val_loss: -2.3824\n",
            "Epoch 296/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4210 - loss: -2.9368 - val_accuracy: 0.3578 - val_loss: -2.3969\n",
            "Epoch 297/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4546 - loss: -2.3033 - val_accuracy: 0.3578 - val_loss: -2.4124\n",
            "Epoch 298/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4521 - loss: -2.7277 - val_accuracy: 0.3578 - val_loss: -2.4266\n",
            "Epoch 299/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4234 - loss: -2.3076 - val_accuracy: 0.3578 - val_loss: -2.4397\n",
            "Epoch 300/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4397 - loss: -3.0569 - val_accuracy: 0.3578 - val_loss: -2.4538\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3358 - loss: -2.8632\n",
            "Test Accuracy: 0.3578\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Confusion Matrix:\n",
            " [[ 0 29  0]\n",
            " [ 0 39  0]\n",
            " [ 0 41  0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        29\n",
            "           1       0.36      1.00      0.53        39\n",
            "           2       0.00      0.00      0.00        41\n",
            "\n",
            "    accuracy                           0.36       109\n",
            "   macro avg       0.12      0.33      0.18       109\n",
            "weighted avg       0.13      0.36      0.19       109\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "dataset_path = \"/content/Housing (2).csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    df[col] = label_encoders[col].fit_transform(df[col])\n",
        "\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(12, activation='swish', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(25, activation='swish'),\n",
        "    tf.keras.layers.Dense(15, activation='swish'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=300, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    }
  ]
}