{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. (1 ponto) Write Python code from scratch to find error metrics of deep learning model. Actual\n",
        "values and deep learning model predicted values are shown in Table 1. Also compare the results\n",
        "with the outcomes of libraries"
      ],
      "metadata": {
        "id": "9Q4Kvbpdm9kA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np0t-1X2ibMI",
        "outputId": "8f7a6323-aaf3-4fde-8e16-3ccca898dfab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.24600000000000147\n",
            "MAE: 0.4600000000000016\n",
            "RMSE: 0.49598387070549127\n"
          ]
        }
      ],
      "source": [
        "def mean_squared_error(y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    mse = sum((y_true[i] - y_pred[i]) ** 2 for i in range(n)) / n\n",
        "    return mse\n",
        "\n",
        "def mean_absolute_error(y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    mae = sum(abs(y_true[i] - y_pred[i]) for i in range(n)) / n\n",
        "    return mae\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = mse ** 0.5\n",
        "    return rmse\n",
        "\n",
        "y_true = [20,30,40,50,60]\n",
        "y_pred = [20.5,30.3,40.2,50.6,60.7]\n",
        "\n",
        "print(\"MSE:\", mean_squared_error(y_true, y_pred))\n",
        "print(\"MAE:\", mean_absolute_error(y_true, y_pred))\n",
        "print(\"RMSE:\", root_mean_squared_error(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. (1 ponto) Write python code from scratch to find evaluation metrics of deep learning model.\n",
        "Actual values and deep learning model predicted values are shown in Table 2. Also compare the\n",
        "results with outcome of libraries\n"
      ],
      "metadata": {
        "id": "Yu625GTOm_5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    c = sum(1 for i in range(len(y_true)) if y_true[i] == y_pred[i])\n",
        "    return c / len(y_true)\n",
        "\n",
        "def precision(y_true, y_pred, class_label):\n",
        "    true = sum(1 for i in range(len(y_true)) if y_true[i] == y_pred[i] == class_label)\n",
        "    predicted = sum(1 for i in range(len(y_true)) if y_pred[i] == class_label)\n",
        "    if predicted == 0:\n",
        "        return 0\n",
        "    return true / predicted\n",
        "\n",
        "def recall(y_true, y_pred, class_label):\n",
        "    true = sum(1 for i in range(len(y_true)) if y_true[i] == y_pred[i] == class_label)\n",
        "    actual = sum(1 for i in range(len(y_true)) if y_true[i] == class_label)\n",
        "    if actual == 0:\n",
        "        return 0\n",
        "    return true / actual\n",
        "\n",
        "def f1_score(precision, recall):\n",
        "    if precision + recall == 0:\n",
        "        return 0\n",
        "    return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "y_true = [0, 0, 0, 0, 0]\n",
        "y_pred = [0, 0, 1, 2, 2]\n",
        "\n",
        "print(\"Accuracy:\", accuracy(y_true, y_pred))\n",
        "precision_class_0 = precision(y_true, y_pred, 0)\n",
        "recall_class_0 = recall(y_true, y_pred, 0)\n",
        "f1_class_0 = f1_score(precision_class_0, recall_class_0)\n",
        "\n",
        "\n",
        "print(\"Precision :\", precision_class_0)\n",
        "print(\"Recall :\", recall_class_0)\n",
        "print(\"F1-Score :\", f1_class_0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzpIz2iXngJN",
        "outputId": "1a620f22-9cd0-499a-f91a-3f2fd735280f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4\n",
            "Precision : 1.0\n",
            "Recall : 0.4\n",
            "F1-Score : 0.5714285714285715\n"
          ]
        }
      ]
    }
  ]
}